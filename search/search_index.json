{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"Blog","text":""},{"location":"index.html#blog","title":"Blog","text":"<p>This is a collation of posts from several blogs I've had since I transitioned from my grad student blog. Reposts of items I've authored from other active blogs are noted. </p>"},{"location":"about.html","title":"About","text":""},{"location":"about.html#about","title":"About","text":"<p>Emma Tosch is a Research Scientist at Northeastern University working in the POEM Lab under the supervision of Dr. Chris Martens. Tosch was formerly an Assistant Professor of Computer Science in the College of Engineering and Mathematical Sciences at the University of Vermont. Prior to graduate school, Tosch worked at a healthcare data startup Recombinant Data, currently part of Deloitte.</p> <p>Tosch works in applied programming languages (PL) research, where she treats the process of language formalization \u2014 especially the design of domain-specific languages \u2014 as a methodological approach to problems not ordinarily considered the domain of PL. She is particularly interested in building languages and tools for data scientists and social scientsts and has recently been applying her work in the cybersecurity domain.</p> <p>Tosch's early work on SurveyMan \u2014 a language and framework for designing, debugging, and deploying surveys \u2014 won first place in the 2014 ACM student research competition at PLDI, a best paper award at OOPSLA 2014, and a 2015 Outstanding Synthesis Award in the College of Computer and Information Sciences at the University of Massachusetts. Her work on PlanAlyzer \u2014 a static analysis tool for programmatically-defined experiments \u2014 was recognized as a SIGPLAN research highlight in 2020 and was selected as a Research Highlight in the September 2021 issue of the Communications of the ACM. </p> <p>Tosch has additionally worked in question answering (natural language processing), evolutionary computation, and explainable AI and has active research interests related to causal inference. </p> <p>Emma Tosch earned her B.A in English Literature from Wellesley College in 2008. She obtained a post-baccalaureate certificate and M.A. in Computer Science from Brandeis University in 2011 before earning her PhD from the University of Massachusetts Amherst in 2020.</p>"},{"location":"news.html","title":"News","text":""},{"location":"news.html#news","title":"News","text":"<p>These news highlights are largely social and collaborative in nature and largely serve as a timeline of my collaborative research activities. I only list here things that I think are significant or interesting.<sup>1</sup> For a complete list of research, teaching, and service activities, please see my cv.</p> July 2025 Collaboration I started working with Northeastern University undergraduate coop student Jason Yu on identifying points in the Mastodon code base for both experimentation and privacy information flows/leaks. July 2025 Presentation  I attended ACM REP with Gwen Lincroft to present Helical. May 2025 Publication Helical: A High Level Language Framework for Specifying Hypotheses and Experiments (coauthored with Gwen Lincroft) has been accepted to ACM REP 2025 May 2025 Presentation I spoke about encoding hypotheses and experiments in Helical at the New England Programming Languages and Systems Symposium Series. February 2025 Presentation Kevin Yang presented our work on DSL support in Jupyter Notebooks at PLATEAU 2025. January 2025 Publication Exploring Support for Lightweight DSLs in Jupyter Notebooks (coauthored with Kevin Yang) was accepted to PLATEAU 2025! January 2025 Dagstuhl I attended my first Dagstuhl Seminar: Grand Challenges for Research on Privacy Documents. I met some very cool people and hope meet and/or collaborate with them in the future! November 2024 Presentation Kevin Yang presented on his coop work and experiences at the Programming Languages Research Seminar. October 2024 Presentation I presented on our Privacy Policies in the Fediverse work at the Digital Economic Security Seminar. July 2024 Presentation I presented on our Privacy Policies in the Fediverse work at the Privacy Enhancing Technologies Symposium. July 2024 Collaboration I started working with Northeastern University undergraduate coop student Kevin Yang on custom DSL support in Jupyter notebooks. In this project I hope we can build out a language server for the Helical languages that can operate in a multi-lingual context. April 2024 Publication Mastodon Administrators\u2019 Experience with Selecting and Using Privacy Policies (coauthored with Luis Garcia, Cynthia Li, and Chris Martens) was accepted to the 24th Proceedings of Privacy Enhancing Technologies. January 2024 Service I agreed to be an associate editor (also called associate chair) for R2 of OOPSLA 2024 and am excited to see what that entails! October 2023 Presentation I spoke about privacy policies on the Fediverse at Northeastern University's Human Centered Computing Community Meeting. January 2023 Presentation I spoke about ASP-powered narrative generation for explaining privacy policies at ProLaLa 2023. December 2022 Presentation I gave the keynote talk at the Learning from Authoritative Security Experiment Results at the Annual Computer Security Applications Conference (ACSAC), organized by David Balenson.\" November 2022 Presentation I gave a talk at UNH on formal language support for experimentation as part of the Robotics Seminar Series (host: Laura Dietz). November 2022 Presentation I had another fun and inspiring visit with friends at GMU, where I gave a talk during the SE lunchtime seminar series on formal language support for experimentation (host: Thomas LaToza). December 2022 Publication Exploring Consequences of Privacy Policies with Narrative Generation via Answer Set Programming (coauthored with Chinmaya Dabral and Chris Martens) was accepted to ProLaLa23 (co-located with POPL23). October 2022 Employment I officially started in a new research position working for Dr. Chris Martens at Northeastern University on narrative generation for privacy policies and am looking forward to further collaborations with them in the longer term! September 2022 Service I began serving as a coach/mentor for three awesome mentees via the NSF's CSGrad4US program. August 2022 Employment I resigned from my tenure-track position at UVM. August 2022 Presentation Longtime collaborator Kaleigh Clary presented our work at USENIX Security 2022. June 2022 Funding My Formal Methods in the Field grant proposal was accepted for funding by the NSF!! (First try!!) <ol> <li> <p>For example, I don't include regular reviewing service on SIGPLAN conference program committees, since for the timeline reflected here, that's a fairly normal/regular occurance.\u00a0\u21a9</p> </li> </ol>"},{"location":"2025/08/20/new-student-new-project.html","title":"New student, new project!","text":"<p>Cross-posted from the Helical project blog.</p> <p>I want to extend a belated welcome to Zixuan (Jason) Yu, a Northeastern University undergraduate student who is working with me on a research coop through December 2025. Jason's project focuses on identifying elements of the Mastodon code base where we might either want to intervene (in order to answer a research question) or where there might be associated privacy considerations.</p> <p>Jason's project combines goals from the Privacy Narratives project and the Helical project. He will be posting here regularly, but before then, let's dicuss the connection between privacy and experimentation.</p> <p>As Donald Campbell wrote in Methods for the Experimenting Society,</p> <p>[Social p]rograms are ... continued or discontinued on inadequate ... grounds[,] ... due in part to the inertia of social organizations, in part to  political predicaments which oppose evaluation, and in part to the fact that the methodology of evaluation is still inadequate.</p> <p>Mastodon as both a software platform and as a collection of communities has less of this inertia. We can think of each Mastodon instance as being a little society. This multiplicity and diversity could present incredible opportunties for empowering citizen social scientists. Insofar as computing systems can be made to have less friction with respect to experimentation, Mastodon's role as a FOSS platform seems ripe with opportunity. Unfortunately, in this context, Campbell's vision for an experimenting society may sound a bit like moving fast and breaking things: an ethos that many Fediverse communities reject. </p> <p>This is NOT what we want! At first blush, it would seen that a notion of trust is missing from Campbell's essay. On closer inspection, however, we find trust's cousin, participant/citizen privacy. Campbell's mentions of privacy focus on scenarios where participants might be unwilling to disclose information to the researcher or research organization; today there are many more parties that may violate trust. We would argue that a violation of trust is the primary harm --- or at least the primary percieved harm --- that experimentation in social networks can cause, and therefore cannot be considered as a separate concern.</p> <p>It is with this context in mind that Jason will be identifying possible intervention points and scenarios that could cause privacy vulnerabilities in the Mastodon code base.</p>","tags":["experimentation","mastodon","privacy"]},{"location":"2025/09/16/jupyter-dsls.html","title":"Jupyter DSLs","text":"<p>Cross-posted from the Helical project blog.</p> <p>One of the broader goals of the Helical project is to make writing, maintaining, and debugging experiments easier and safer for the end-user through a novel domain-specific language. However, learning a new formal language can itself contribute to the difficulty of encoding an experiment. Therefore, we are intersted in mitigating the effects of language learning/novelty. To this end, a Northeastern coop student (Kevin G. Yang) investigated the suitability of using Jupyter notebooks as an execution environment for experiments last year.</p> <p>Jupyter notebooks are commonly used by empiricists. If we want empiricists to use Helical, then it would make sense to integrate it into empiricists' computational workflow. Kevin began investigating the feasibility of adding such support for features such as syntax highlighting and code completion to Jupyter. This actually turned out to be a surprisingly difficult task!</p> <p>Kevin ended up doing a deep dive into the Jupyter code base and issue database, resulting in an experience report and tutorial that he presented internally at the Northeastern Programming Research Lab's seminar series and externally at PLATEAU 2025. While his coop focused on a specific implementation task, the work led us to ask new research questions. For example, we were somewhat surprised by the breadth of tooling empirical scientists were using and that there was demand for custom syntax highlight organically in the Jupyter user base \u2014 conventional wisdom in the PL community is that DSLs are a bit niche! Thus, rather than focusing on Helical specifically, we broadened the task to DSL support in Jupyter more generally. </p> <p>At the start of his coop, I had envisioned Kevin integrating Helical into Jupyter and then pivoting to a reproduction study. However, as he was working on the project, he became increasingly interested in visualization and usability. We were hoping to perform a user study in Summer 2025 to further investigate some of the research questions that arose and perhaps send a conference paper submission out to CHI or UIST; that thread was put on hold as Kevin continues his career exploration journey. </p>"},{"location":"2025/09/17/dsl-usability-research.html","title":"DSL Usability Research","text":"<p>Cross-posted from the Helical project blog.</p> <p>In my previous post, I asserted:</p> <p>...learning a new formal language can itself contribute to the difficulty of encoding an experiment.</p> <p>This statement was based on assumptions, intuitions, and folk wisdom. I started digging into the DSL usability research to see if I could find explicit support for this statement. This blog post is about what I found. </p> <p>Suppose I have a DSL for a task that was previously manual. I want to conduct a user study. I decide to use some previously validated instrument to measure differences in perceived difficulty of encoding/performing a task (\\(D\\)), and vary the method used to code the task (\\(M=\\text{DSL}\\) vs. \\(M=\\text{manual}\\)). Suppose there is no variability in task difficulty for now: the specific task is fixed for the duration of the study, i.e., is controlled.</p> <p>Ideally, I'd like to just measure the effect of \\(M\\) on \\(D\\); we are going to abuse plate notation<sup>1</sup> a bit and say that the following graph denotes \"method has an effect on percieved difficulty of performing a specific task for the population of experts in the domain of that task:\"</p> <pre><code>flowchart LR\n  M(\"Method ($$M$$)\")\n  subgraph ppl [domain experts]\n      D(\"Percieved Difficulty of Task ($$D$$)\")\n  end\n  M --&gt; D\n</code></pre> <p>The first obvious problem is that \\(D\\) is a mixture of some \"inherent\" difference due to \\(M\\) and the novelty of the method/context/context/environment/situation (\\(N\\)). We have not included \\(N\\) in our model; let's do so now: </p><pre><code>flowchart LR\n  M(\"Method ($$M$$)\")\n    subgraph ppl [domain experts]\n      direction TB\n        N(\"Novelty ($$N$$)\")\n    D(\"Percieved Difficulty of Task ($$D$$)\")\n    end\n  M--&gt;D\n  N--&gt;D</code></pre> Conducting a na\u00efve study results in \\((D \\vert M=\\text{manual}, N = 0)\\) vs. \\((D \\vert M=\\text{DSL}, N \\gg 0)\\). This is why we have the study participants perform a training task first: it's an attempt to lower \\(N\\) as much as possible, i.e., to control for novelty. <p>Training tasks are obviously not unique to DSL research; however, there are other tactics for reducing novelty that are unique to programming systems. For example, it seems obvious that IDE features like syntax highlighting and autocomplete that are part of a \"normal\" programming environment would reduce the value of \\(N\\); so would integrating the DSL into the target users' existing toolchain/workflow.</p> <p>If we allow the task to vary, then our model needs to include another potential cause for \\(D\\):</p> <pre><code>flowchart LR\n  M(\"Method ($$M$$)\")\n  C(\"Task Complexity ($$C$$)\")\n  subgraph ppl [&amp;nbsp;&amp;nbsp;domain experts]\n    direction TB\n    N(\"Novelty ($$N$$)\")\n    D(\"Percieved Difficulty of Task ($$D$$)\")\n  end\n  M --&gt; D\n  N --&gt; D\n  C --&gt; D</code></pre> <p>The details of how we represent \\(C\\) matter: whatever scale we use, it contains a baked-in assumption that for any two tasks \\(t_1\\) and \\(t_2\\) where \\(t_1\\not=t_2\\), but \\(C(t_1)=C(t_2)\\), we can treat \\(t_1\\equiv t_2\\). This  is a big assumption! What if there are qualitative differences between tasks not captured by the complexity metric that influence \\(D\\)? In that case, we may want to use a different variable to capture \\(C\\), perhaps a binary feature vector, or maybe we want to split \\(C\\) into a collection of distinct variables. Maybe task complexity isn't objective but subjective, in which case we would want to include in our domain experts plate. Maybe we want to forego \\(C\\) altogether and instead treat tasks as a population we need to sample over, e.g.,</p> <pre><code>flowchart LR\n  M(\"Method ($$M$$)\")\n  subgraph ppl [&amp;nbsp;&amp;nbsp;domain experts]\n  subgraph tasks [tasks]\n    direction TB\n    N(\"Novelty ($$N$$)\")\n    D(\"Precieved Difficulty of Task ($$D$$)\")\n  end\n  end\n  M --&gt; D\n  N --&gt; D</code></pre> <p>I have plenty more to say and would love to iterate on the design of this hypothetical user study, but I am going to stop here because the above diagram feels like something that should already be established in the literature. Like a lot of folk wisdom, it's suggested, implied, assumed, and (I think!) generally accepted, but so far I have not found any explicit validation of the above schema. That doesn't mean it isn't out there; it means that (a) there isn't a single canonical paper accepted by the community as evidence and (b) where the evidence does exist, it's embedded in work that primarily addresses some other research question.</p> <p>So, for now, I am putting together a DSL usability study reading list of works that I think touch on this fundamental problem in meaningful ways. I consider Profiling Programming Language Learning and PLIERS: A Process that Integrates User-Centered Methods into Programming Language Design seed papers and have gotten recommendations from Andrew McNutt, Shriram Krishnamurthi, and Lindsey Kuper. Please feel free to add to this (or use it yourself!). I look forward to writing a follow up post on what I find. :)</p> <ol> <li> <p>While the plate notation here looks similar to the output that Helical produces for HyPL code, the specific graphs are more precise than those that Helical can currently produce. For example, only \\(D\\) is embedded in the domain experts plate. Helical's current implementation would place both \\(M\\) and \\(D\\) in this plate.\u00a0\u21a9</p> </li> </ol>"},{"location":"2020/12/15/advising-expectations-basics.html","title":"Advising Expectations Basics","text":"","tags":["advice","hidden curriculum"]},{"location":"2020/12/15/advising-expectations-basics.html#advising-expectations-basics","title":"Advising Expectations Basics","text":"<p>While I've mentored many students over the years,  I'm entering a new phase in my career where I will be officially advising graduate students. This post  is a first pass on what that means to me.</p> <p>Note that some undergraduates will be assigned to me as your curriculum or major advisor. That is a very different kind of advising relationship from the one described here, and is not covered below.</p>","tags":["advice","hidden curriculum"]},{"location":"2020/12/15/advising-expectations-basics.html#the-advisor-advisee-relationship","title":"The Advisor-Advisee Relationship","text":"<p>I expect my advisees to come from a diversity of backgrounds and life experiences. Some of you may never have worked in a professional setting before. Some of you may have years of experience in industry or  government. Some of you may never have had any kind of relationship with an adult who wasn't a teacher or a parent. Some of you may have managed teams, courted clients, or negotiated contracts. </p> <p>No matter your background, there really is no professional relationship quite like the PhD advisor-advisee relationship. Everyone starts with holes and has something to learn. The best analogy I've seen is that  it is an apprenticeship. Apprenticeships have typically been common in the trades. I believe the analogy  is helpful when thinking about the PhD as traditional labor, in the sense of production. It's deficient  when we think of the PhD as knowledge work, and as mentorship. One way I have come to think about this  tension is that advising is about guiding and managing production, and mentorship is about guiding  and managing intrisic/personal growth.</p> <p>Note that while we often talk about your advisor also being a mentor, that is, in practice, often not the case, and I am not sure it is actually desirable for it to be! Sometimes the directives of an advisor conflict with the directives of a mentor, and asking one person to be both can cause distress and  potentially a loss of trust for the advisee. Therefore, it can be helpful for the advisee to ask  themselves: am I interacting with my PhD advisor as a supervison, or as a mentor?</p>","tags":["advice","hidden curriculum"]},{"location":"2020/12/15/advising-expectations-basics.html#advisors-as-managers-time","title":"Advisors as Managers: Time","text":"<p>Generally speaking, most students are funded to work 20 hours per week for the term of their contract,  either as a TA (teaching assistant) or an RA (research assistant).  Regardless of how you spend your time, it is important to discuss up front with your work supervisor (i.e., the instructor of the course if you are a TA, or your research supervision if you are an RA) how that time should be allocated, and what the contractual obligations are. For example, are you  expected to work up to 20 hours per week, an average of 20 hours per week, or a total of the  number of weeks in your contract, times 20 hours per week? Are there major deadlines around which you  should not travel? Are there deliverables or meetings you are expected to attend?</p> <p>In my experience, most supervisors don't speak explicitly about hours, but rather set expectations that  most closely comport with the third interpretation (i.e., as if you have a total number hours expected). This can mean that there are times when there is little work and times when you are expected to engage  in \"sprints,\" where your week hours will exceed 20 hours per week.</p> <p>I strongly encourage students to discuss expectations with their supervisor ahead of time. I personally plan to do this with my students. I strongly prefer consistency in hours for a variety of reasons (e.g.,  it's easier for students with health issues or familial responsibilities to plan around them, I don't think  sprints are mentally or physically healthy, etc.), but this tends to require more planning up front (i.e.,  acting rather than re-acting) and can puts more burden on the supervisor. Supervisors tend to have a lot  of responsibilities and wear many hats, so staying organized and on top of things can be challenging.  This is especially true of new professors; I will do my best to prioritize my students over other  responsibilties, but know that this can be challenging to actually pull off! The important thing for  students to remember is that you should feel empowered to have these conversations early and often!</p> <p>Finally, note that assistantships  benefit the advisee both financially (i.e., you are paid) and educationally (i.e., they are training you  to teach/do curriculum development, or they are training you how to do research).</p>","tags":["advice","hidden curriculum"]},{"location":"2020/12/15/advising-expectations-basics.html#advisors-as-mentors-raships","title":"Advisors as Mentors: RAships","text":"<p>In the general case, you should not be spending, on average, more than the time you are paid on your assistantship. The major exception to this is when you have an RAship that overlaps with your  dissertation topic (or, for very junior studnets, research area you think might provide the foundation of your dissertation). Advisors tend to encourage students to find an overlapping RAship because it's good  for the student (making progress on the project is equivalent to making progress on your degree, and  removes the overhead of context-switching) and because it's good for the advisor (you have incentives to go above and beyond the outlined work because you now have a personal stake in it). </p> <p>In the ideal world, an RAship would work something like this: you start graduate school funded on your advisor's project, or on a more senior student's project.  You put in your 20 hours, and over the course of your first year, you are largely  working on someone else's project, learning how to do research. Ideally, you'd work with your advisor to set learning goals and output goals. Then, once you find your feet, you work with your advisor to find funding for the research you want to do. </p> <p>However, there are many ways that this process can go awry. In particular, since it relies on your growth as a researcher, advising here can become intertwined with mentorship. </p> <p>For example, you may never find a research area or question that motivates you. Sometimes students discover that they don't actually like research. Sometimes students discover they don't like the working style of their advisor. There are many things that can make the working relationship rocky. </p> <p>A common failure mode is that the student discovers that the topics that really interest them, or the questions  that really motivate them, are outside the scope of what their advisor cares about, or has expertise in. Part of developing an independent research identity is learning how to pitch your research idea to your supervisor. However, it is not the obligation of a supervisor to invest in a new research area because  their student has interest there. Just as it is important for students to recognize that they are entitled to  boundaries from their research supervisor, it is important for studnets to recognize that their supervisors are entitled to boundaries from their student's research interests. This is why many schools advertise to  prospective graduate students that it is easy to change advisors. </p>","tags":["advice","hidden curriculum"]},{"location":"2020/12/15/advising-expectations-basics.html#your-advisor-is-a-coach-not-a-parent","title":"Your advisor is a coach, not a parent","text":"<p>Each advisor's and advisee's needs will be different, so it is critically important to continually  communicate needs and expectations. It can be quite challenging for students when they need one  thing from a supervisor and another thing from a mentor. </p> <p>This is issue is particular pronounced when students struggle. Consider the following scenario: a student is having personal struggles that are affecting their work performance on a funded project that  has a deadlines and deliverables. The advisor then must step in to complete the work. The student needs compassion and encouragement, but they have also put other students' funding in jeopardy because the  advisor had to use time that was allocated to writing grants on delivering on this grant. In this particular (not terribly uncommon) case, the advisor may feel conflicted between their roles as work supervisor  and mentor. </p> <p>It can be tempting for students to think of their advisors as parental surrogates -- after all,  the heirarchical and often patriarchal nature of academia makes it all too easy for everyone to buy into this model of mentorship. I prefer to think of advisors as coaches: we want our team to do their best (and preferably win!), but most of all, we want to support each team member in their professional and personal goal. Good teams are more than the sum  of their parts, and good coaches know when to deliver tough truths and when to step out of the way.  Good coaches also understand that getting a good game out of the team isn't about the coach. Finally,  good coaches understand that athletes sometimes need personal coaches and trainers, and aren't threatened  by that. </p>","tags":["advice","hidden curriculum"]},{"location":"2020/12/15/advising-expectations-basics.html#are-you-my-advisor","title":"Are you my advisor?","text":"<p>Finally, I want to make it explicit what I mean when I consider someone to be my advisee. I consider an advisee to be  someone whose degree progress I am directly and strictly greater than 50% responsible for, or someone  whose research I directly or indirectly supervise. </p> <p>This means that if I am on a committee that determines your fate (e.g., thesis committee or curriculum committee), I am not necessarily your advisor. If I agree supervise your thesis, but you never follow up, I am not  necessarily your advisor. If we talk about research, but either party never follows up, I am not your advisor. </p> <p>If you aren't sure, just ask!</p>","tags":["advice","hidden curriculum"]},{"location":"2020/12/15/advising-expectations-basics.html#acknowledgements","title":"Acknowledgements","text":"<p>This post is the result of culmination of many years of thinking about the power differential between adivsor and advisee, but most recently I owe the distinction between advising and mentoring to discussions with  Sara Kingsley.</p>","tags":["advice","hidden curriculum"]},{"location":"2023/02/09/reproduction-vs-replication.html","title":"Reproduction vs. Replication","text":"","tags":["rep","metaphysics","helical"]},{"location":"2023/02/09/reproduction-vs-replication.html#reproduction-vs-replication","title":"Reproduction vs. Replication","text":"<p>In 2020 or so, ACM swapped its definitions of reproducibility and replicability to be more in line with the broader social sciences community. I see the reasoning for the swap, but I don't think that the new definition is quite right either. The crux of the issue is that definitions both communities are using are a shorthand that doesn't map appropriately across communities. </p> <p>As a result of discussions with the National Information Standards Organization (NISO), it was recommended that ACM harmonize its terminology and definitions with those used in the broader scientific research community, and ACM agreed with NISO\u2019s recommendation to swap the terms \u201creproducibility\u201d and \u201creplication\u201d with the existing definitions used by ACM as part of its artifact review and badging initiative. ACM took action to update all prior badging to ensure consistency.</p> <p>Prior to 2020, the ACM used the following definitions; we only produce the shorthands below, but discuss the longer text descriptions at the end of the blog post. </p> <ul> <li>Repeatable: same team, same experimental setup For computational experiments, this means that a researcher can reliably repeat her own computation.</li> <li>Replicable: different team, same experimental setupOld: For computational experiments, this means that an independent group can obtain the same result using the author's own artifacts.New: For computational experiments, this means that an independent group can obtain the same result using artifacts which they develop completely independently.</li> <li>Reproducible: different team, different experimental setupOld: For computational experiments, this means that an independent group can obtain the same result using artifacts which they develop completely independently.New: For computational experiments, this means that an independent group can obtain the same result using the author\u2019s own artifacts.</li> </ul> <p>So far as I can tell, the only argument for the swap that I\u2019ve found has been that \u201cthis is how things have been done in most other fields\u201d and to facilitate communication. While I agree that this is important (esp. as someone who works with social scientists!), I believe that the there is a strong semantic foundation for reconsidering how we communicate the definitions that does not rely on the shorthand above. This foundation relies on how computing generates experiment replicates.</p>","tags":["rep","metaphysics","helical"]},{"location":"2023/02/09/reproduction-vs-replication.html#reproducibility-generally","title":"Reproducibility, generally","text":"<p>A longer explanation: the dominant definition of reproducibility is that a different team runs the same experiment (in computing, same code; in non-computational contexts, same high-level experimental procedure) over the same data. I'd note that there is already some ambiguity in the terminology, since \"experiment\" can refer to each of the following, increasing scopes:</p> <ul> <li>Just the treatment assignment procedure.</li> <li>Just the data collection procedure (i.e., treatment assignment + logging covariates and outcomes).</li> <li>The experimental task (i.e., data collection + analyses)</li> </ul> <p>The \u201csame data\u201d argument is important not for its surface value, but because that data was produced over a fixed set of replicates. Replicates are related to the notion of units, which have the extremely helpful definition of being \"one of something.\" Context gives units a greater meaning: they are things that we do  something to, e.g. analyze functions of, randomize into treatments, or experiment within or on. I won't get into the specifics here, but when we hope to generalize beyond the specific units participating in our experiment, we need to expand the set of units via replication. Notably, this could mean selecting a sample from a population of interest (e.g., website users in an A/B test), but it could also mean replicating the experimental context (e.g., plots of soil in an ecology experiment). Thus, replicates is a broader, more general term than what we typically think of as sampling.</p> <p>When a social scientist \u201creproduces\u201d an experiment, they are essentially auditing an experiment in service of reproducing the result.  Furthermore, I'd argue that in social science, the result folks care about is whether...</p> <pre><code>----------------------------------     \n| the data collection procedure, | (A) \n----------------------------------     \n|\nV\n----------------------------------     \n| the actual data collected, and | (B)\n----------------------------------     \n|\nV\n----------------------------------     \n|     the analyses performed     | (C)\n----------------------------------     \n|\nV\n----------------------------------     \n|    support the **findings**    | (D)\n----------------------------------     \n</code></pre> <p>...stated in the paper. Re-running data collection is intrinsically about replication (which we are going to punt on for now). Let's assume that the authors collected the data faithfully according to the reported procedure.</p> <p>In a world where all the relevant data is digitally stored and analyzed, we can see how \"reproduction\" essentially refers to running the same scripts over the same data. Sometimes doing so reveals choices (e.g., excluding certain data) that may invalidate the previously reported results. Prior to the widespread availability of statistical software, analyses had to be performed manually, so researchers were essentially hand-calculating the outcomes using the procedures described in papers, using the original data. </p> <p>Thus we can see how \"different team, same setup\" makes sense as a shorthand for reproducibility; we are focusing on the integrity of (C)-&gt;(D), given (B).</p>","tags":["rep","metaphysics","helical"]},{"location":"2023/02/09/reproduction-vs-replication.html#replicability-generally","title":"Replicability, generally","text":"<p>Similarly, when a social scientist replicates an experiment, they are producing new data, specifically by collecting a new sample and are thus operating over a different set of replicates. If the experiment ocurred entirely in the digital space (e.g., on Amazon's Mechanical Turk) and each step of the procedure is written in executable code, someone could feasibly press a button to replicate (A)-&gt;(B)-&gt;(C)-&gt;(D), where the integrity of this inference chain depends on (1) nothing crashing, and (2) the chain (C)-&gt;(D) comporting with the community's understanding of the variability of the outcomes being measured. </p> <p>Note that in a replication, we expect to not reproduce findings exactly. This is due to the variability that caused us to replicate in the first place! </p> <p>Strictly speaking, when a social scientist re-runs an experiment - especially if that experiment is not online \u2014 they may or may not use the same procedure, so the requirement that the code be the same typically isn't there; it need only comport with the high-level data collection procedure. For example, treatments that were randomly assigned in the original study must also be randomly assigned in the new one. </p> <p>The fundamental problem of causal inference is that we can only ever observe one treatment condition per replicate at any one time. Due carryover effects, maturation, and other time-realted factors outside of our control, social scientists often cannot run the same experiment on the same unit (espeically if that unit is a person!) twice. This differs from how we have classically thought of computing experiments, where we can \"reset the universe\" at will. Thus, in social science, any time you collect new data, you are necessarily operating over new replicates, in a new setup (either explicitly, or Ship of Theseus-style). </p> <p>One of the principles of causal reasoning is that because the assignment mechanism must be unbiased, it does not causally influence outcome. Therefore, so long as (1) independence of assignment holds and (2) any preconditions for the analyses they intend to run holds (e.g., the same set of variables is recorded). Thus we might think of replication as either</p> <ol> <li>(C)-&gt;(D) given (A)-&gt;(B'), or </li> <li>(C)-&gt;(D) given (A')-&gt;(B')</li> </ol> <p>Thus, it makes sense that when social scientists say \u201cdifferent team, same setup\u201d they mean reproduction...because no new replicates are being generated! Similarly, when social scientists say \u201cdifferent team, different setup,\u201d they mean replication because a different setup in traditional offline social science contexts requires identifying new replicates and generating new data. </p>","tags":["rep","metaphysics","helical"]},{"location":"2023/02/09/reproduction-vs-replication.html#where-these-definitions-break-down-in-computing","title":"Where these definitions break down in computing","text":"<p>My argument is that oftentimes while the setup of a system under test during artifact evaluation is \u201cthe same,\u201d the system on which reviewers are running the \u201creproduction\u201d is actually itself a replicate! Consider the famous -O2/-O3 optimization example as our canonical systems performance comparison and suppose that I run the same scripts on the same benchmarks; if I am re-running these studies locally, am I running a reproduction or a replication? </p> <p>Let's start with the assumption that we have the original outcome (e.g., timing/performance) data that appeared in the paper. Using the classical definitions of reproduction vs. replication, a strict reproduction would only re-run the data analysis for the original system, not generate new data locally! This follows the letter of what a reproduction means...or is it?</p> <p>No matter how many possible effect modifiers might be controlled for, at the end of the day, these sorts of papers are by and large being run on just one replicate, which makes them completely incomparable to reproduction studies in the sense that other fields mean the term. Even without the replicate terminology, I'd argue that most competent researchers in our field know intuitively that merely analyzing one machine's performance numbers is the moral equivalent of waiving a paper through on \"runs on my machine\" (where \"my\" refers to the author!). </p> <p>So what is reproduction, in this context? Well, I'd argue that reproduction is not yet meaningful for this kind of study! Why? Because the study is in need of replicates and any manner of re-running the experiment on a different machine, such that that different machine is an appropriate context (e.g., not a LISP Machine) and the experimental conditions are the same counts as a replicate, i.e., the different machine is itself a new replicate, producing new data!</p>","tags":["rep","metaphysics","helical"]},{"location":"2023/02/09/reproduction-vs-replication.html#reality-in-computing","title":"Reality in Computing","text":"<p>I suspect that if we, as a community, were to explain to other experimental/computational scientists that we write papers on the basis of results from an single machine, they would be horrified. So is our entire field screwed?</p> <p>Despite my dire tone, I'd emphatically say: No! We have a unique problem in computing where it can be both infeasible and (with high confidence) unncessary to replicate experiments at the scale we see in other sciences. For example, it may infeasible to obtain many copies of computers having representative workloads to test the kind of systems experiments we might want to run. One could argue that the availability of cluster computing makes this task easier. On the other hand, a cluster may not be a representative sample of system state. Perhaps instead we have every student in a lab or classroom run the same experiment in service of replication, prior to artifact evaluation?</p> <p>Enforcing behavioral change is hard. I'd argue that there is additional value to Artifact Evaluation beyond the awarding of badges - evaluators can function as active research participants, contributing their measurements as replicates to the paper itself!</p>","tags":["rep","metaphysics","helical"]},{"location":"2020/11/17/research-philosophy.html","title":"Research philosophy","text":"<p>Everyone should have an elevator pitch about their research. When we start out, that pitch is very focused on a particular project, problem, or technique. As time passes, we form a more expansive research vision that can encompass new domains, related problems, and complementary techniques, but still ties everything together in a coherent philosophy, with a long-term goal. My pitch is: programming languages (PL) and software engineering (SE) form the methodological foundation for next-generation advancements in data-driven scientific inquiry. Just as scientific instruments made new experiments and discoveries possible, so too will new programming languages, systems, frameworks, and platforms.</p> <p>Therefore, my perspective is to work on the fundamental tooling that allows us to answer a variety of research questions. I'm guided by the following questions:<sup>1</sup></p> <ul> <li>What are the core abstractions of a problem or domain and how do they combine? (PL)</li> <li>How do we encode these abstractions in programs or software systems? (PL/Systems)</li> <li>Once encoded, how do we know the system is correct? What properties should it have? (PL/SE/Security/Privacy/Fairness/Statistics)</li> <li>Once encoded, how do we get people to use our system (and use it correctly!)? (SE/HCI/Security)</li> <li>Once we have a system, what questions can we answer now that we couldn't answer before? (DS, ML, CSS, etc.) </li> </ul>"},{"location":"2020/11/17/research-philosophy.html#abstractions","title":"Abstractions","text":"<p>Throughout my research career, I have been interested in developing domain-specific languages (DSLs) for tasks when appropriate. Some common DSLs that people may know are SQL, CSS, and even spreadsheets like Excel! What differentiates DSLs from so-called \"general-purpose programming languages\" is that their design is tailored to a specific task: they may certain things much easier to do than others. We refer to the set of things that are easy to do as the base set of abstractions, and the language restricts or enables how those abstractions may combine. </p> <p>A critical feature of language design is recognizing whether it is germane to the problem in the first place! Not all problems or domains necessitate a new language. Instead, in my research, I work to understand the problem or domain first, and then identify and encode (typically in consultation with a domain expert) language abstractions and rules for combining those abstractions. Sometimes this process of formalization can reveal interesting properties about the domain not previously considered. Sometimes these properties are a byproduct of moving a perviously manual or offline task to an encoded, automated one. </p> <p></p> <p>For an example of this approach, see my SurveyMan work.</p> <p>While the SurveyMan project has been on hold for several years, I am looking to work with students on some related work/research questions in both programming languages (specifically related to blocks languages) and computational social science (specifically related to crowdsourcing). I am particularly interested in students who would like to address security questions (related to adversarial behavior during data collection) and privacy questions (related to protecting participants' information). Please reach out if you are interested!</p>"},{"location":"2020/11/17/research-philosophy.html#language-design-and-system-building","title":"Language Design and System Building","text":"<p>Once we have identified the core set of abstractions and how they combine, my work usually involves implementing them in an actual system! This step of the research often involves some iteration with the abstraction design process, and is coding-heavy. One of the concrete benefits to students who work with me is that they have the opportunity to hone their programming skills while also doing research.<sup>2</sup> For larger systems, the software architecture can become a research contribution, especially if that software architecture generalizes to related problems. </p> <p></p> <p>This is an example of ongoing work on the software architecture for explanation systems for autonomous agents.</p> <p>This is ongoing on work that includes opportunities for students interested in probabilistic programming languages. Please reach out if you are interested!</p>"},{"location":"2020/11/17/research-philosophy.html#correctness","title":"Correctness","text":"<p>The advantage of encoding abstractions is that they facilitate proving properties about programs. We can use the base abstractions and the rules for how they combine to show inductively that properties of interest hold. Traditionally this has meant devising a type system, which categorizes pieces of programs into sets, and showing that the system is sound, according to some predefined notion of \"soundness.\" Students familiar with types in programming languages may recognize type safety as a kind of soundness, where the procedure that categorizes these pieces of programs never \"gets stuck\" and always arrives at the same answer. </p> <p>There are many properties that can be proven about programs, other than type safety. For example, static taint analysis uses information flow to prove that private data does not leak, while type state provides the abstractions necessary to reason about interactions between a program and the persistent mutable state of the executing machine (e.g., a file is properly closed). Both of these examples are about properties not normally associated with type inference, but address the correctness of programs nonetheless.</p> <p>The PLAID Lab has expertise in proving properties of programs, in the domains of type safety, security, privacy, and fairness. My future collaborations will reflect the expertise present here at UVM.</p>"},{"location":"2020/11/17/research-philosophy.html#people-centric-evaluation","title":"People-Centric Evaluation","text":"<p>During the design phase, I work with domain experts to understand what tools potential users prefer. While this process of including users in the design loop has been informal, I look forward to working with collaborators and students who are interested in taking a more human-factors approach to the evaluation of new systems. I am particularly interested in better understanding the usability of the language, tools, and systems I design.</p> <p> For example, the output of my PlanAlyzer static analysis tool is either the above \"pretty-printed\" text, or csvs that can be loaded into a database. The above notation uses the conventions of experimentalists, but this output does not scale, and may not be understood by non-experts.</p> <p>I am particularly interested in collaborating with folks who study, or are interested in studying, how to better present large volumes of information to users, especially when users must make decisions in the presence of these data.</p>"},{"location":"2020/11/17/research-philosophy.html#applications","title":"Applications","text":"<p>Finally, since I am interested in designing better platforms for facilitating basic research, I enjoy working with folks who have interest or expertise in specific application areas. In a way, my collaborators could be seen as \"clients\" of my software, except that there is the goal of discovering novel problems at the intersection of software and their domains, rather than simply delivering solutions. This means that my collaborations are cooperative.</p> <ol> <li> <p>This very question-first approach to research is deeply influenced by one of my PhD supervisors, Dr. David Jensen, who has always been an exemplar of how to view computing as science.\u00a0\u21a9</p> </li> <li> <p>Often students expect research to involve more programming; while it can, students may go for long periods of time without practicing. This can become a problem if, years into a PhD program, you realize you need to write software to do your research, but lack the experience or skills to do it yourself.\u00a0\u21a9</p> </li> </ol>"},{"location":"2022/12/11/leaving-uvm.html","title":"Leaving UVM","text":"","tags":["personal"]},{"location":"2022/12/11/leaving-uvm.html#leaving-uvm","title":"Leaving UVM","text":"<p>In August 2022, after almost two years as a tenure-track Assistant Professor of Computer Science, I resigned from my position at the University of Vermont. This was not my preferred path, but something I felt I had to do in light of some family stressors and an increasingly untenable mismatch in values between me and my institution. Thus I joined my Millennial brethren in the Great Resignation.</p> <p>My current position is intentionally transitory in nature. I don't know if I will be in this role (or one like it) for three months, a year, or three years. What I do know is that, rather than seeking the impossible criteria of \"work-life balance,\" moving forward I will be seeking \"job-life balance.\" I make this distinction because while the work of being a professor is largely the same everywhere, the nature of the job differs dramatically, depending on institution. </p> <p>Though I left my professoring job, I will never stop the work: I've continued mentoring students, pursuing collaborations, and producing research results.  It hasn't been easy, and I stress constantly about financial stability and security, but I am making it work.  I realize that not everyone who leaves a TT academic position can remain connected to academia. Thus, I count myself very lucky and have immense gratitude for the robust network of mentors who have given me their time, advice, an ear, and in some cases, professional connections and job opportunitites. </p> <p>While I haven't ruled out moving back to a tenure-track position, I do intend to be very deliberate about that process. I've described the current state of academic hiring as a bit like a shotgun wedding, when what I want is a long engagement or arranged marriage.  I am quite fortunate that, as a US citizen, I have considerably more freedom to make choices about my employment and take my time to pursue the kind of environment where I can effectuate my goals and values. </p> <p>So what is it exactly that I'm looking for? I've thought a lot over the years about what our ethical \u2014 rather than operational \u2014 duties are as faculty.  We tend to view the acquisition of faculty jobs as competitions, as prizes to be won, and because we imagine the academy to be egalitarian in nature, we think of the people in those positions as being \"worthy\" of the research (and to a much lesser degree, teaching) standards of our field.  We think about faculty in terms of being \"deserving\" of their jobs and this is reflected in our annual evaluations, promotion, and tenure processes.  All of these evaluation criteria are about catering to the standards and preferences of the people above us in the org chart. In some places there are empirical criteria; in others for better and for worse, it's fuzzier. In all places, there is an uneasy tension between how we want or imagine things to work and how they actually work. </p> <p>I would like to work in a place that carves off time to discuss and be deliberate about the bigger questions: what is the role of a university in today's world? How do we balance economic considerations with a university's mission? What are our objectives in undergraduate education? What is the purpose of graduate training? How do we convey to students the limitations of what faculty can do for them? How do we set expectations and minimize harm in our interactions with students, staff, and folks who are generally more vulnerable than we are?</p> <p>I prefer to think about the faculty job as an obligation to a community.  Faculty positions are fundamentally service and care positions. Therefore, I want to be in a place that understands and promotes a care mentality from the top-down. This is something that is both exceedingly hard to measure and impossible to verify during the job search process when committees are overtaxed and undersupported. </p> <p>When I say \"care mentality,\" I am fundamentally talking about working in an environment that values difference and dissent. It's about promoting a growth mindset and listening mentality amongst those with power. It's about understanding that the most important part of the job is not the papers we publish or the grants we acquire, but how we spend the limited time we have and making the many hours we spend on the job worth living, because if we have a care mentality, those other empirical measures of success will come. This means being in a place where admitting you are afraid or feeling insecure is seen as a stength. It's about being in a place that takes self-compassion seriously and treats professional development on par with personal development. </p> <p>You see, I do think there's something to the notion of being \"worthy\" of a faculty position. However, to me it's not about whether your past accomplishments caused you to beat out someone else.<sup>1</sup> Instead it's about asking faculty to live up to the ideal of what a professor can be. Maybe it's because I don't come from an academic family and so I have a more idealized notion of what higher education is, but I think where we really fail to live up to our potential is in our collective lack of wisdom and compassion. We can't leave it up to individuals to purse these values on their own; for our work to really matter, we need to pursue them together. </p> <p>If this resonates with you, I do have academic materials available: </p> <ul> <li>Research</li> <li>Teaching</li> <li>DEI</li> </ul> <p>I am currently weighing some options, but I am also trying to make all decisions independently in an effort to prioritize fit and moving toward something new, rather than picking a path to avoid fear, discomfort, and uncertainty. I've compared the past two years to losing my faith; there is something sacred in what we do in higher education and whether I find my way back to the faith or learn to live without it, I will always be trying to do work that matters and pay forward the opportunities I've been given.</p> <ol> <li> <p>Don't get me wrong, I do generally love ambition and the spirit of competition, to the point where my partner won't play non-cooperative board games with me anymore...\u00a0\u21a9</p> </li> </ol>","tags":["personal"]},{"location":"2020/12/14/regarding-graduate-student-service.html","title":"Regarding Graduate Student Service","text":"","tags":["advice","hidden curriculum"]},{"location":"2020/12/14/regarding-graduate-student-service.html#regarding-graduate-student-service","title":"Regarding Graduate Student Service","text":"<p>People who know me know that I am a huge proponent of treating academia  as work. However, we do not work in a system that is particularly  compatible with a modern notion of labor. The following advice attempts to  balance how things should work (i.e., compensating people on  the basis of their labor) with how they actually work (i.e., the reliance  on unpaid work that is high value but not valued highly).</p> <p>We can typically break service obligations into three categories: lab, department/college/university (internal) and external. I will discuss lab service last, since it can be the trickiest to manage.</p>","tags":["advice","hidden curriculum"]},{"location":"2020/12/14/regarding-graduate-student-service.html#internal-service","title":"Internal service","text":"<p>I typically encourage graduate students in their first two years to do only internal service. What is internal service? It's service work within your department/college. The benefits of doing internal service and prioritizing internal service are:</p> <ol> <li>It gives students a chance to meet other students and build a support network.</li> <li>It builds camaraderie between students who serve.</li> <li>It (usually) gives students a chance to meet faculty who are neither their advisors nor their professors, whom they may want to ask for letters later on.</li> <li>It can empower students to feel like they have control over their academic and immediate social environments. </li> <li>It can be a \"trial run\" for external service. </li> </ol> <p>The major theme here is using internal service as a structured way to get to learn more about a department and its norms. There are many kinds of internal service. As an example, my PhD program had the following opportunities:</p> <ul> <li>Organizers of Monday Morning Coffee and Thursday Tea. These were primarily low-effort weekly social events. If you were a shy person, it was a great way to break the ice with people. </li> <li>Graduate Union Representative. This was my primary service over the years: our graduate students were unionized and serving made it easier for me to be in the loop for contract negotiations. </li> <li>Seminar organizers and volunteers. There were a variety of seminar series for different CS sub-disciplines when I was in graduate school. These seminars ranged from being entirely student-run (e.g., the Machine Learning and Friends Lunch) to entirely faculty-run (e.g., the Systems Lunch). Typically student organizers and volunteers had the chance to select and then later meet speakers. While these positions were certainly work, they were considered very desirable, due to the networking opportunities they afforded.</li> <li>Graduate representative to the faculty. This was a must-do service activity for any graduate student interested in faculty jobs. GradReps attended faculty meetings, interviewed faculty candidates, and were allowed to vote on non-RPT (reappointment, promotion, and tenure) matters. This is one of the best ways to see how the sausage of academia gets made. </li> </ul> <p>Internal service should immediately benefit you, the student. If you are, for example, volunteering at a seminar, but you are just doing setup and cleanup and have no special opportunitites to meet the speakers, you may want to consider putting your efforts elsewhere.</p>","tags":["advice","hidden curriculum"]},{"location":"2020/12/14/regarding-graduate-student-service.html#external-service","title":"External Service","text":"<p>I typically recommend that students wait until they feel more secure in their position before doing external service. This might mean having published their first research paper, having reached PhD candidacy, or having completed their coursework. The reason is that stakes tend to feel higher for external service, and the load also tends to be higher. It is not uncommon to feel overwhelmed in the first year or so of graduate school, so I am a huge fan of minimizing obligations and focusing on two things in the early years: (1) building your internal PhD support network and (2) growing your expertise in your subfield. </p> <p>At some point, every student will start to feel more confident, and that is a very good point to begin doing external service. This may happen earlier for some folks than others. Some external service obligations are more intense than others, but all external service is important for building your reputation in your resaerch community. I recommend starting to incorporate external service in the following order:</p> <ol> <li>Student volunteering at conferences. Some students will begin doing this quite early. I think it can be beneficial early on to get a sense of what different research communities are like and what they work on. However, once you are sure of your research area, it is not worth being a student volunteer until you are at a point where you intend to attend conferences regularly. Once you do start attending conferences, being a student volunteer can be an easy way to meet other students. You will eventually \"grow out\" of this, though. I don't recommend being a student volunteer more than three times in your field; after that, people should start asking you to do more intensive external service. </li> <li>Student reviewing. Different subfields have different approaches to student reviewing. In SIGPLAN conferences, students who have not published at a conference are typically introduced to reviewing via Artifact Evaluation. In ML/AI venues, where the number of submissions is very high, many conferences have started asking for students to self-nominate as reviewers. I do not recommend reviewing papers for conferences until the latter half of your PhD. </li> <li>Conference/Workshop Organization. There are some annual workshops or small co-located conferences that involve student organizers, where being asked to chair that workshop or conference is considered a great honor. There are other circumstances where, e.g., you and your advisor may prepare a written proposal that you must submit for review. This kind of service is very labor-intensive and I only recommend it in the last two years of your PhD. </li> </ol>","tags":["advice","hidden curriculum"]},{"location":"2020/12/14/regarding-graduate-student-service.html#lab-service","title":"Lab service","text":"<p>Lab service is necessarily low-impact and can involve anything from taking notes during lab meetings, to maintaining the lab website, to mentoring junior students. Lab service can be highly beneficial to students for building camaraderie and trust. However, poorly distributed lab service can completely undermine mutual trust and respect. </p> <p>One of the unfortunate truths of graduate school is that certain work just needs to get done, and it is simply easier for faculty to lean on \"reliable\" students they know will follow through. In a fair world, faculty would keep track of the balance between opportunitity and service and ensure that all students do their fair share, while no students are unduly burdened. Unfortunately, this is not common practice. In light of that, students must learn to advocate for themselves. This can be quite tricky, since students and faculty each have incomplete pictures of the situation. </p>","tags":["advice","hidden curriculum"]},{"location":"2020/12/14/regarding-graduate-student-service.html#exploitation","title":"Exploitation","text":"<p>It will always be necessary for students to stand up for themselves. The key is doing so politically. While exploitation can happen in any context, in my experience it is most egregious and difficult to manage when the parties involved know each other well: trust and familiarity are often preconditions.</p> <p>That said, one person's exploitation is another person's opportunity -- only you can know if the situation is bad for you. </p> <p>No matter who are you, when asked to do unpaid work, continually ask yourself: what am I getting out of this? Consider the above example, where you are doing setup and cleanup for a seminar series. If you enjoy doing this work as a break from you day, then no one should make you feel bad for not \"getting more out of it!\" Everyone finds satisfaction in different activities and it is perfectly legitimate to spend time on activities that don't translate to an impressive line on a c.v. or networking opportuntities if you find them fulfilling. </p> <p>Remember: someone who exploits your labor now, or fails to see your contributions now, is not going to write you a strong recommendation later. </p>","tags":["advice","hidden curriculum"]},{"location":"2020/12/14/regarding-graduate-student-service.html#quitting-unpaid-work","title":"Quitting unpaid work","text":"<p>Quitting service can be politically tricky. Often the folks you report to are fulfilling service obligations themselves and can fail to advocate for themselves. In such circumstances, it's probably best to not come out and say: I feel exploited. It's better to simply say: this position is no longer working for me, and I need to scale back or quit. </p> <p>If the service obligation has no fixed end date, then you should be able to quit whenever. Term-based service obligation is usually for a fixed length of time, and you should generally try to complete your term before quitting. If you cannot, be firm in your end date. Even if the person you report to is overworked and exploited themselves, they should not be operating in an environment where the margins are so thin that one person quitting prematurely ruins everything. </p> <p>Finally, remember that in academic computer science, no one's livelihood is on the line if we have to quit a service obligation. If it were really that important, we'd be paid!</p>","tags":["advice","hidden curriculum"]},{"location":"2021/08/06/speaking-is-hard.html","title":"Speaking is Hard","text":"<p>This post is going to be more personal essay than documenting views that can masquerade as advice. I am considering writing more posts in this style, as a representation of a particular time and place. Inspired by this series.</p> <p>Talking about technical work \u2014 and research especially \u2014 is hard.  When we say this, we often elide the why and as a result perpetuate the idea that there is something inherently difficult about computer science.  This post is about a view I've long held, that computing is just as much about learning a dialect and culture as it is about the technical work we do.</p>"},{"location":"2021/08/06/speaking-is-hard.html#mise-en-scene","title":"Mise en sc\u00e8ne","text":"<p>In today's world of Hackathons and Girls Who Code, I came to computing comparatively late. I didn't program in my youth, I didn't go to math camp, and I wasn't, like many folks I met in college, a talented youth, which I presume would have exposed me to programming. This was totally normal for a 90s kid! I was raised with propaganda that sexism was a solved problem. It was against this backdrop where, while I'd done fine \u2014 and at times even excelled! \u2014 in my STEM courses in my younger years, I decided to change my major to English Literature in college, mostly because it made me feel smug and cultured at parties.<sup>1</sup></p> <p>Unsurprisingly, I used to feel like a fraud in those courses because my professors thought I was quite insightful and clever, but I always felt like I was faking it. I knew how to mimic the styles of writing they admired, I could read criticism in depth and map out the more arcane perspectives, and I generally knew how to repeat back enough analysis that would align with the professor or the reading, while inserting enough of my own thoughts to appear original. I knew I was only a good writer because I was a depressive, socially awkward, and misanthropic child who preferred to read and write and think strategically about communication over actually communicating. I wasn't a \"natural\" at these things<sup>2</sup> \u2014 they took considerable time and effort \u2014 but more powerful people seemed to think I was and the mask was to my benefit, so I went with it.</p> <p>When I took an introductory programming course in my penultimate semester in college, I found myself in the middle of the pack, but enjoyed the actual work of sitting at a computer and coding so much more than writing papers that felt like sophistry.<sup>3</sup> I thought, this is something I could stand to do for 40 hours a week. I always planned to be some kind of writer or a lawyer, but coding seemed like a sufficiently enjoyable profession with better pay than the former and less debt and stress than the latter. </p> <p>I got into computing in my 20s during a time when all tech interviews asked what coding projects you did in your spare time. That's a topic for a different post, but my main feeling was one of culture shock. There are certain things that can be more apparent to an outsider, such as how CS had a view of itself as being filled with people with no social skills but tons of passion, when in fact there was a clear culture, language, and hierarchy.  Despite the fact that I've \"officially\" been in computing for over a decade now, I still feel like an interloper in a foreign land wondering who can tell that I don't belong and that this isn't my mother tongue. </p>"},{"location":"2021/08/06/speaking-is-hard.html#writing-is-hard-but-speaking-can-be-harder","title":"Writing is hard, but speaking can be harder","text":"<p>My secret weapon in graduate school was many years of writing experience. My super-special secret weapon was how I thought about writing, which was very clinically and operationally. My writing meta-game allowed me to adapt to CS technical writing with relative ease, which was incredibly important since everything else was a slog.<sup>4</sup></p> <p>Writing is a skill, but given that papers are rarely written by a single author, attribution can be challenging. Even single-author papers go through peer review, and are often the result of iteration and feedback. I quite like this feature, since it can emphasize the work over the self. On this axis, however, speaking is in direct contrast \u2014 we rarely question who spoke an utterance upon hearing it.<sup>5</sup>  The social status of a person who says something insightful or clever will immediately improve if the speaker has enough confidence and insouciance; people will hold that person in higher esteem and make inferences about their acumen. Speak in an awkward or imprecise manner at your peril. Mistakes feel fatal.</p> <p>The stakes for spoken speech are thus quite high, especially for people who do not fit the current cultural profile of clever person in CS. I was never one to ask questions during class (make no mistake, I had plenty), and recall male peers from grad school criticizing classmates who did (always female), for their \"stupid questions.\" I remember going in to office hours and fumbling over the words to describe what I did not understand, and having the professor latch onto the part of the question I actually did understand, which of course made me wonder how little they thought I knew. </p> <p>Over time I found people I trusted, mostly in my labs. I was fortunate to work with several professors during my PhD who really listened to me work through problems, rather than dismissing me as an outsider for not knowing vocabulary or for struggling to articulate my thoughts. I learned how important it was to work in a lab with peers, and how even casual communication about research could be a minefield. At the end of my PhD I was especially lucky to have a cohort of female colleagues with whom I'd chat about research regularly. </p> <p>What shocked me about the lab environment at the end of my PhD shouldn't be shocking at all \u2014 having a space of people who, no matter what I said, would never think I was less for having said something poorly, foolish, or even (gasp!) incorrect finally gave me the space to feel truly comfortable in a research environment. That comfort wasn't just about feelings \u2014 it created a virtuous cycle wherein we kept talking with each other about research. For the first time I was getting regular practice in the art of research conversation. Everyone should have the benefit of this environment.</p>"},{"location":"2021/08/06/speaking-is-hard.html#casualty-of-the-pandemic","title":"Casualty of the pandemic","text":"<p>Some of this story may come as a surprise to people who know me well. </p> <p>Trouble speaking, especially in high-stress situations, is a common consequence of a lack of practice, and a lack of practice can often be attributed to a lack of social or psychological safety. Since the start of the pandemic, I've secured a TT position, written and defended my dissertation, moved to a new state, and started a new job. I used to commute on the bus every day and on most days chat with one of my labmates on the way in. We would chit chat about papers at lunch, run ideas by each other, and seamlessly meander from discussing the latest boulder problem at our gym to an interesting research discussion we saw on Twitter. We'd pitch paper ideas to each other and outline big, ten-year research visions.</p> <p>Now I can go most days where the only person I actually speak to is my partner. I haven't given a public talk since my defense a year ago, and virtual conferences have no appeal to me. I feel increasingly disconnected from a broader research community. I've tried to use Twitter to connect with people, but it's been much easier leverage Twitter as a casual social media site than to engage in serious conversation on it. I've reached out to some folks over the past year to chat about possible research collaborations, but it's been painful. I went from being conscious of how hard it was to articulate my research plan to downright struggling to make sense to the other party. </p> <p>All the while, I have not stopped writing. In fact, the only time I feel good about myself and my work is when I sit down to write. Virtual interpersonal interaction makes me feel like a loser, but at least all of the paper reviews and grant feedback has been effusive about my writing. </p>"},{"location":"2021/08/06/speaking-is-hard.html#hope-for-the-future","title":"Hope for the future","text":"<p>I know that this is a byproduct of the pandemic and remote work. I believe \u2014 and must hope \u2014 that it will pass. However, it reminds me so much of my early days in computing, where I struggled to understand and be understood. </p> <p>While this is personally challenging, the silver lining is that it does come at a good time. I will soon have research students working with me and being reminded of how daunting it can be to start. It's good to viscerally feel the impact of not \"speaking the language\" of the community so that I can be intentional about the environment I create for my students. </p> <p>Fundamentally, no matter how I feel, I have all the signifiers of someone who belongs \u2014 I did, after all, end up in academia. My students will undoubtedly differ from me in ways I will not be able to anticipate. My hope is that with honesty, practice, and a commitment to listening \u2014 really listening \u2014 I will be able to foster an environment where they will feel free to speak. </p> <ol> <li> <p>I started as an Economics major, but I went to college in part to become what I thought was a learned person, and I didn't feel any more learned after my freshman year, hence the change of major.\u00a0\u21a9</p> </li> <li> <p>Is anyone, though?\u00a0\u21a9</p> </li> <li> <p>In high school I wrote a document called \"Bullshitting Writing Assignments\" that was structured as an infomercial and was meant to be a pastiche of Strunk and White. A classmate actually used it to write her college essays. Youth.\u00a0\u21a9</p> </li> <li> <p>I'd note that some of that ease wasn't just the experience of having spent years of writing nearly every day, but also the experience of having earned years of positive feedback on my writing. I certainly had several CS professors pontificate on their idea of good writing and tell me some very silly things, but I had a good foundation of confidence in my skills (even if I did sometimes feel like a fraud) that I lacked in my mathematical reasoning and coding.\u00a0\u21a9</p> </li> <li> <p>Although I will surprise myself with words that sound quite unlike me, and am no longer surprised when I hear my words coming from someone else's mouth, these cases speak to a different issue. Even if you are repeating yourself, choosing the correct time and emphasis is a skill and can be wielded to impress.\u00a0\u21a9</p> </li> </ol>"},{"location":"2020/12/10/forms-of-address.html","title":"Forms of address","text":"<p>Choosing the wrong forms of address is the fastest way to make a bad  impression over email. However, it is one based on norms and therefore  is not typically explicitly taught. </p> <p>In the general case, we can capture how you should choose the form of  address via flow chart:</p> <pre><code>                        --------    \n                        | Prof.|\n                        --------\n                           /\n                          /\n                     Yes /\n                        /\n---------------------- /\n| Has \"Professor\" in |/                 -------\n| title or job desc. |\\                 | Dr. |\n---------------------- \\                -------\n                        \\               /\n             No/Not sure \\         Yes /\n                          \\           /\n                    -----------------/                -------\n                    | Has Doctorate |                 | Mr. |\n                    -----------------\\                -------\n                                      \\                /\n                           No/Not sure \\           He /\n                                        \\            /\n                                        ------------/   She    -------\n                                        | Pronouns | --------- | Ms. |\n                                        ------------\\          -------\n                                                     \\\n                                  They/Other/Not sure \\\n                                                       \\\n                                                       -------\n                                                       | Mx. |\n                                                       -------\n</code></pre> <p>If you do not know the answers to these questions, take a minute or  two to search the internet to try to find out. If you are still unsure,  pick the most formal title that is appropriate given the context. For  example, in a university setting, choose \"Prof.\" If you are writing to  someone who works in a field that has many people with doctorates,  choose \"Dr.\"</p>","tags":["hidden curriculum","advice"]},{"location":"2020/12/10/forms-of-address.html#prof-vs-dr","title":"Prof. vs. Dr.","text":"<p>This one can cause some confusion: not all folks who have doctorates  work in universities, and not all folks who work in universities have doctorates. </p> <p>Outside of a university, you may start by assuming that anyone who does industrial research has a PhD and thus should be referred to as \"Dr.\" Inside a university, you may assume that anyone who teaches should be referred to  as \"Prof.\" Some people who teach in a university may have the title  \"Lecturer\" or \"Instructor.\" If you don't know the culture of forms of  address at the institution of the person you are addressing, default to the most formal form and let the person you are writing to correct you.</p>","tags":["hidden curriculum","advice"]},{"location":"2020/12/10/forms-of-address.html#how-students-should-address-professors","title":"How students should address professors","text":"<p>When unsure, students should always choose the most formal form of address. This is a sign of respect; not adhering to this rule sends a signal about a lack or respect or an assumed familiarity that the recipient may not  be comfortable with.</p> <p>In computer science, students are often encouraged to refer to faculty by their first names. This practice may not carry over to other disciplines.</p> <p>If someone refers to themselves using a different name or title in response  to an email, you should feel comfortable using that name or form of address in future emails. </p>","tags":["hidden curriculum","advice"]},{"location":"2020/12/10/forms-of-address.html#how-professors-address-each-other","title":"How professors address each other","text":"<p>A professor may refer to another professor by first name. As mentioned above, in computer science, it is normal for everyone to be on a first-name basis. However, in the general case you should not assume the form of  address one professor uses to talk about another carries over to students. </p> <p>I will generally address other professors/lecturers/instructors at my  home institution by first name. I will also address  professors/lecturers/instructors in computer science at other institutions by first name. However, I will generally use titles when addressing  professionals at other universities who are not in my discipline. This is done to signal deference and a lack of familiarity with other disciplines' cultural norms.</p>","tags":["hidden curriculum","advice"]},{"location":"2020/12/10/forms-of-address.html#why-forms-of-address-matter","title":"Why forms of address matter","text":"<p>It can sometimes feel like forms of address enforce a heirarchy or about  \"showing off\" credentials. If you feel this way, ask yourself: why?<sup>1</sup></p> <p>As mentioned above, forms of address are signs of respect. They are also about setting boundaries, and communicating expected boundaries. For  example, if you address me as \"Ms.,\" I assume that you know little to nothing about me, professionally. The only people who call me \"Ms.\" are trying to sell me something. :) </p> <p>There are many groups of people who have historically been excluded from higher education, from having the possibility of earning titles like \"Prof.\" and \"Dr.\" When folks (especially students!) fail to use these titles, it  can feel like they are diminishing the person's accomplishments.  UVM's own Dean<sup>2</sup> KC Williams has written about the  deleterious effects of this lack of respect in academia on her, as a  Black woman:<sup>3</sup></p> <p>Some students will refuse to address you respectfully, but they will do so with a smile. They may even attempt to call you by your first name after you have introduced yourself to them professionally with the expected \u201cDr.\u201d or \u201cProfessor\u201d preceding your last name -- on the first day of class, writing it on the board and in the syllabus.</p>","tags":["hidden curriculum","advice"]},{"location":"2020/12/10/forms-of-address.html#how-you-should-address-me","title":"How you should address me","text":"<p>If you are a graduate student, or we have connected in a research capacity  (e.g., have met at a conference), you should feel free to address me by my  first name (Emma). If we have never met before and you are a student (esp.  if you are a student reaching out about a class), you should refer to me  as Prof. Tosch in your first email. If we have never met, and you are  reaching out outside a university/education context, I am Dr. Tosch in your first email. </p>","tags":["hidden curriculum","advice"]},{"location":"2020/12/10/forms-of-address.html#when-to-use-mrs","title":"When to use Mrs.","text":"<p>In a professional setting? Never. Just don't. </p> <ol> <li> <p>I serendipitously wrote this post the day before the Wall Street Journal published an opinion piece on why Dr. Jill Biden should not be referred to with the \"Dr.\" title. For a full discussion of the context surrounding that news event, see this Vox explainer.\u00a0\u21a9</p> </li> <li> <p>\"Dean\" is a title in academia.\u00a0\u21a9</p> </li> <li> <p>Black women area demographic group in the US who have historically been excluded from higher education, and who today still face systemic barriers, and often discrimination once they arrive in academia.\u00a0\u21a9</p> </li> </ol>","tags":["hidden curriculum","advice"]},{"location":"2021/01/02/transitioning-my-twitter-account.html","title":"Transitioning my Twitter account","text":"<p>I've been on and off Twitter for over a decade, and have recently decided to deactivate my personal account (@emmatosch) and transition  over to using my professional account (@toschemma) exclusively, effective 1/12/20. This post walks through  my rationale; it's less social media quit-lit and more of a reflection of how I need to update how I see me to be more in line with how others will see me in my new job.</p>"},{"location":"2021/01/02/transitioning-my-twitter-account.html#usage-over-time","title":"Usage over time","text":"<p>Twitter was only three years old when I'd joined, and I mostly knew marketing people on it, which meant my feed was qualitatively quite different from what it is now. I've gone through periods where my feed was mostly about political news,  to periods where it was entirely standup comedians vetting new materials, to it being entirely dominated by people from tech.  A few years ago I came to realize that Twitter was the best place to learn about post-doctorate positions, and began using it more regularly, following an assortment of academics I might want to work with. </p> <p>Around the time I was adding more academics to my feed, I experienced some challenges in my PhD. I laid low for a while, but  when I felt ready to start getting out there again, I decided to use Twitter in a very specific way: to be seen, and the  strategy I took to be seen was to show my personality, no matter how weird it may be, and to  not take anything that seriously. For exanple, this was one of my last tweets; the only context necessary is the pandemic:</p> <p></p>"},{"location":"2021/01/02/transitioning-my-twitter-account.html#microblogging-vs-blogging","title":"Microblogging vs. Blogging","text":"<p>Now, I feel I should point out that I did have an internet footprint before I started engaging more on Twitter.  I had been blogging about my research (as a PhD student) for a while at that time.  I used blogging to try out ideas, work through concepts, and generally as a research notebook, and for technical documentation. Critically, I used blogging to just get myself to write, even if the content containted inaccuracies.  I assumed no one was really reading my blog, which is mostly true!</p> <p>Blogging had a very specific function for  me, and I used Twitter quite differently. I often felt uncomfortable, out of place, or socially anxious at conferences and  other in-person venues where people talk about their research and become known. As someone who came to computing later, it took time to learn the social norms of the field, and that learning process could be deeply uncomfortable.  Twitter, on the other  hand, gave me the chance to re-engage with the community in what felt like a very low-stakes way. Interactions are public,  and expectations about the topics you weigh in on are invariably lower -- because Twitter is a very open platform, anyone  can express any thought about any topic! To be concrete: if a group of professors are talking about their research, community policies, teaching, etc. at a conference reception, you don't know if you are actually welcomed to join. However, if these  conversations happen on Twitter, everyone has the expectation that some rando might pop in. </p>"},{"location":"2021/01/02/transitioning-my-twitter-account.html#curating-my-twitter-persona","title":"Curating my Twitter persona","text":"<p>So, back to how I used Twitter: like I said, I decided to be seen.  However, popping into existing conversations was  challenging because I had been out of the loop for some time. Instead, I decided I would just try to tweet funny/absurd/silly  things about life, pop culture, computing more broadly, etc. As far as I can tell, this approach actually worked! </p> <p>This might sound overly sentimental, but I have come to cherish these interactions over the years: they feel like some of the most human professional interactions I've had. Twitter can be  fun. However, as I've transitioned from being a student to being a faculty member, I've started to think about things  differently. </p>"},{"location":"2021/01/02/transitioning-my-twitter-account.html#becoming-a-more-public-figure","title":"Becoming a more public figure","text":"<p>I've been thinking a lot about what it means to reconcile the abrupt change in my public image  (i.e., graduate student to tenure-track faculty) with how I see myself. One thought I keep coming back to is that, even though I  still have much to do and much to prove, my new job carries institutional authority and structural power that I need to be mindful of. </p> <p>The specific question I've been mulling over is: what do I owe current and future PhD students, and how can I ensure that my public presence on fora such as Twitter reflects that? I think the answer to the first half of that question is:  I owe it to students to work towards being the kind of professor we all wish we had -- someone wiser and more centered than anyone of us actually are. For the second half of the question, I've come to realize that that means being mindful about the image I put out into the world. I worry that my Twitter persona --  snarky weird \"kid\" mumbling under her breath in the back of the class -- will increasingly alienate more junior people who  only see me as someone with intitutional power, not as someone who struggled to get where she is, who at one time had  more in common with struggling students, but who has rapidly lost perpsective once she \"made it.\"  No matter how hard being a junior faculty member may be personally, it is still a position of privilege. </p> <p>Maybe more talented users of social media can make the transition from being seen as someone who fights The Man to being seen as someone who is The Man, but I'm not sure I can.  Instead, I've decided that this next stage of my life is going to involve some intentionality in the crafting of my public persona, and the cleanest way to do that is to deactivate my personal Twitter account. It's like a new haircut for the Internet age. So, here is a snippet of what you can expect to see do vis a vis @toschemma:</p> <ul> <li>Post the usual academic announcement stuff</li> <li>Amplify my students' successes </li> <li>Amplify the work of people junior to me</li> <li>Publicly comment on controversies that occur within my field/subfield, especially at the request of my students or junior researchers who have less power than I do</li> <li>Use my account to promote practices that build healthy mental and emotional habits in graduate school</li> </ul> <p>I am going to try to keep my account topical. For example, I will generally not be tweeting, nor re-tweeting about politics,  unless it is directly related to computing or graduate school.  This is less about avoiding politics and more about providing consistency in the topics I tweet about. Any  \"hot takes\" should leverage my unique competencies: e.g., I do not currently work professionally in politics, activism, or  organizing, and don't have much to add to the conversation. However, if there is a story about tools for experimental design used by campaigns, I might weigh in.</p> <p>Thanks to everyone who has engaged with me on Twitter @emmatosch in the past! I'll still subtweet, make shitposts, and generally tweet random thoughts without context that no one actually reads until 1/11/20. Gotta start somewhere! It's been a blast!</p>"},{"location":"2022/08/18/non-cooperation-in-experiments.html","title":"Non-cooperation in experiments","text":"<p>Last week, Kaleigh Clary presented her work, Stick it to the Man: Correcting for Non-Cooperative Behavior of Subjects in Experiments on Social Networks at USENIX Security. One of the things I really like about this work is the focus on analysis and implications of non-cooporative actors in network experiments from a PL/systems perspective. </p> <p></p>","tags":["experimentation","security","adversaries"]},{"location":"2022/08/18/non-cooperation-in-experiments.html#the-problem-this-work-addresses","title":"The problem this work addresses","text":"<p>One of the core contributions of this paper is a statistical correction for adversarial behavior with respect to experimentation in a networked (e.g., social media) environment. To see why corrections are both necessary and non-trivial, let's first consider the more typical view of experimentation. Suppose you participate in psychological and market research studies you find on Craigslist for cash. You are certain that you are in an \"experiment\" of some kind upon starting the study and that your actions are being observed and will be analyzed; none of this should be surprising.</p> <p>Now, there may be some circumstances under which you do not participate in good faith. Maybe you disagree with the motivation behind the study. Maybe upon arrival you realize the experimenters are asking more from you than you're willing to give but it's not enough to quit and lose the cash. Maybe you've done a lot of these experiments and think it would be fun to mess the researchers. Maybe there are reasons only known to you. No matter what the reason, you decide to do something different, e.g., act randomly, lie, give the opposite answer from what you think they want. </p> <p>In an experiment or study of a sufficient size, we would not expect such non-cooperative behavior to have a significant effect, so long as each actor behaves independently. The idea is that each individual's non-cooperative behavior will be distributed iid throughout the population, making that behavior tantamount to noise. </p> <p>Of course, the iid assumption is a rather strong one. There are two major cases where this could be a problem:</p> <ol> <li>When participants coordinate their behavior and </li> <li>When a single non-cooporative participant's behavior influences unsuspecting participants be revealing information about their treatment or their response. </li> </ol> <p>The former is the traditional purview of a security conference; its statistical correction involves removing those participants from the population. This is a bummer, since it affects statistical power, but ultimately post-hoc detection isn't so bad. </p> <p>The latter is what Kaleigh's work is about. In the former case, once we classify and remove a non-cooporative participants from the sample, we're done. However, in the latter case, there is a kind of leakage to unsuspecting participants due to the experimental design \u2014 Kaleigh has talked about this as a kind of Sybil attack. </p> <p>So what about the experimental design causes this leakage? Well, often in experiments in a networked setting one cannot simply assign individuals to experimental conditions at random due to the fact that participants interact with each other, violating what's known as SUTVA (but what the casual, non-causal computer science reader can think of as a kind of interference). The idea is that participants may be clustered into strongly connected communities such that random assignment of experimental treatment to individuals in those communities won't work \u2014 due to the connectedness, some participants may actually be exposed to both their own experimental treatment and someone else's! Under such a circumstance, we would need to throw out this data, since we cannot separate the effect of one condition versus another.</p> <p>To address this issue, researchers use what's called cluster random assignment where, instead of assigning experimental conditions at random for each individual, they assign experimental conditions at random for each community (i.e., everyone in the same community gets the same assignment). This is great because it increases power. This is not so great because it makes such designs more vulnerable to adversarial or non-cooporative behavior \u2014 a participant with high connectivity within the community cluster can have outsized influence on the quality of the data collected. </p> <p>Kaleigh's work developed a statistical correction for this bias, but it also showed how vulnerable communities are to well-connected non-cooporative actors. In fact, it takes surprisingly few non-cooperating nodes having the right network placement (i.e., connectivity) to render an experiment essentially useless. </p>","tags":["experimentation","security","adversaries"]},{"location":"2022/08/18/non-cooperation-in-experiments.html#implications-for-pl-researchers","title":"Implications for PL researchers","text":"<p>Online social networks are important platforms not only for social science researchers, but also for systems researchers broadly, including folks interested in PL. Platforms don't just enable socialization, but also the exchange of ideas, goods, and services \u2014 i.e., resources. They are increasingly being seen as execution environments where high-stakes automated transactions happen.</p> <p>The future of these platforms is one where policies that govern human behavior may be generated programmatically. Interpretable DSLs for platform policies are one way we might do this responsibly and experimentation will be critical for the development and automation of such policies. Thus understanding threat models to experimentation is of paramount importance. </p> <p>Kaleigh's work addresses the vulnerability of a particular experimental design to attack. An experimental design is a particular procedure or policy for assigning treatment to experiment participants and is often associated with a family of estimators for an outcome of interest. What I find fascinating about Kaleigh's work is how it illustrates the tradeoff between a design that increased power by reducing variability, but came at a cost vis a vis its vulnerability to attack. </p>","tags":["experimentation","security","adversaries"]},{"location":"2022/08/18/non-cooperation-in-experiments.html#ethics","title":"Ethics","text":"<p>One line of inquiry that came up repeatedly during the conference were questions from security researchers about protecting vulnerable populations. There was an implicit question about why we should help platforms like Facebook collect data on users. Our position is twofold: (1) the alternative to experimentation is policy by fiat, which is probably not so good, and (2) experimentation is a method and should be thought of as a separate concern from data collection, privacy, and transparency. What platforms do with experimental data is a different question from how they experiment. </p> <p>A major unspoken concern is folks' discomfort with deception. Unfortunately for end-users, many experimental questions rely on deception \u2014 or at least asymmetry in information. </p> <p></p> <p>Our position is that there are better ways to build trust with end-users and obtained informed consent to participate in experimentation \u2014 this is a platform-level policy issue, not one that can be solved via statistical correction. To that end, I look forward to relaying what Erin McBride has been working on this summer in a future blog post!</p>","tags":["experimentation","security","adversaries"]},{"location":"2022/08/18/non-cooperation-in-experiments.html#future-posts-on-this-topic","title":"Future posts on this topic","text":"<p>Here are some forward links to future blog posts on this topic. Feel free to tag <code>@AppliedPL</code> on Twitter if you would like to see one of these sooner rather than later!</p> <ul> <li>Story of this paper's genesis</li> <li>Breakdown of the estimators</li> <li>Web demonstration of the analysis</li> <li>Relationship to related work published recently</li> </ul> <p></p> <p></p>","tags":["experimentation","security","adversaries"]},{"location":"2022/07/20/answering-the-important-questions.html","title":"Answering the important questions","text":"<p>Here in the MaPLE lab, we treat the techniques students cultivate in their programming systems classes as general methods for answering a broad range of research questions that arise in and around software when it is used in nontraditional ways.  As a result, students without formal training in the techniques we use often ask: \"What is PL?,\" whereas those with training often ask: \"How is what you do PL?\" </p>"},{"location":"2022/07/20/answering-the-important-questions.html#what-is-pl","title":"What is PL?","text":"<p>Everyone in PL eventually has the experience of telling someone their research area is programming languages and having that person respond with \"Oh? What programming language do you study?\" This is understandable; many students' first exposure to PL is still via a programming paradigms course, which have highly variable content.  However, the main gist is that there are a variety of ways we can design what a language looks like (i.e., its primitive components and the rules for combining them, or its syntax) and these design choices are supposed to make some things easier than others. Some of the features we believe to be impacted by design are obvious, like usability (e.g., the heated debate about parentheses of Lisp vs. spaces of Python) and some are less obvious, like performance and correctness. Most of these benefits are not just about the language's syntax, but also include reasoning about its semantics, or how we should interpret what the program means or does. </p> <p>However, quite a bit of PL research these days it not about general-purpose programming languages at all!  I'll get more into this in the section below, but for now it can be helpful to just think about PL more abstractly. One of the best high-level views of PL I've seen is Eelco Visser's PLMW 2019 talk, wherein he described PL as being about \"getting stuff for free.\" One mechanism for \"getting stuff for free\" is designing domain-specific languages (i.e., DSLs, languages designed for a limited and highly specialized domain, not necessarily for human end-users) such that we can say meaningful things about them without actually running them, using existing tools and techniques.  </p> <p>When we analyze programs without actually running them, this is called static analysis. Intuitively, if you can ask important questions about the range of a program's behaviors before running it, you have higher confidence that fewer bad things will happen. Terms like \"important questions\" and \"bad things\" are purposefully vague because they depend on the particular domain you are working in. The more we can cleverly encode information in a language's syntax, the easier it becomes to analyze programs statically. One popular goal in PL research is to find ways to catch problems early.  </p> <p>{{ image(src=\"img1.png\",           alt=\"Image showing a rough timeline of PL-related tasks in the following order: language design, interpreter implementation, writing a program in the language, running static analyzer, running the program, and finally observing output or error.\",           caption=\"A sketch of the ordering of some PL-related tasks you might do.\",          class=\"full\") }}</p> <p>One common point of confusion for newcomers who have a background in computer science but not PL: we know that answering arbitrary questions about the execution of an arbitrary program is undecidable. In PL, we are typically interested in specific questions about arbitrary programs written in a specific language.</p>"},{"location":"2022/07/20/answering-the-important-questions.html#how-is-what-you-do-pl","title":"How is what you do PL?","text":"<p>PL as a field has become increasingly interdisciplinary, as researchers apply PL concepts to problems not ordinarily thought of as within scope. Much of the work we do in MaPLE is deeply interdisciplinary, reflecting this reality.  One perspective on the evolution of PL that I like is the treatment of languages as part of a programmer's broader toolkit, exemplified in this 2018 CACM article. They mention two affordances of this perspective on PL that I like:</p> <ul> <li>Enable creators of a language to enforce its invariants, and</li> <li>Turn extra-linguistic mechanisms into linguistic constructs. </li> </ul> <p>We enforce invariants through language design choices, such as prohibiting certain operations (e.g., recursion), making certain constructs atomic (e.g., parallel operators), and equipping programs with complementary systems that encode \"extra\" information beyond what's necessary to execute the program (e.g., types). </p> <p>\"Extra-linguistic\" mechanisms refers to \"stuff\" that isn't ordinarily part of a language, but you nevertheless need to be able to reason about programs. In this lab, we often work in contexts where the end result is some kind of statistical analysis. Those analyses are often only valid (in theory, if not in practice!) if certain assumptions about data generating process are true. </p> <p>Now, statisticians have devised incredibly clever ways to make up for violations to these assumptions. In this lab, we don't strive to devise new corrections; instead, we try to understand existing problems via assumptions and corrections, and then design systems (such as programming languages, libraries, and frameworks) to either prevent the assumptions from being broken or make diagnosis easier. In that way, we use PL principles to push diagnostics earlier, making it so that we fail faster (a good thing because we don't waste resources!). </p> <p>{{ image(src=\"img2.png\",          caption=\"\",          alt=\"\",          class=\"full\")}}</p> <p>{{ image(src=\"https://i.imgflip.com/6necwk.jpg\",          alt=\"To the left to the left. Everything that can, gets moved to the left\",          class=\"full\",          caption=\"\") }}</p> <p>Because much of what we do involves deep dives into different data-driven domains, the PL principles that drive our approach aren't always immediately apparent. In the general case this is a good thing \u2014 we don't want to burden domain experts with a novel field when their goal is to just get something done! However, we do uncover interesting properties of programs in these domains that have implications for PL methods. This creates an exciting feedback loop between PL and the domains we work in. </p> <p> First lab blog post! Read it to find out what MaPLE is about. :)</p> <p></p>"},{"location":"2022/07/09/writing-every-day.html","title":"Writing every day","text":"","tags":["advice"]},{"location":"2022/07/09/writing-every-day.html#writing-every-day","title":"Writing every day","text":"<p>The PhD is a professional degree and like all professional degrees, it prepares students for what are fundamentally jobs in communication. While the core of the work is technical \u2014 e.g., programming/coding, writing proofs, performing empirical analyses \u2014 that work is all for naught if you cannot communicate the fundamental insights and significance of your work to others. </p> <p>This is why one of the things I always tells new graduate students is to write every day.   Many new graduate students struggle under the lack of structure, inherent uncertainty, and deep questions about motivation in their pursuit of the PhD, so I believe these skills and coping strategies can be useful for most students. </p> <p>There are many kinds of written communication that we should all practice every day. I still have a \"write for an hour every day\" in my daily to-do lists! A timer is ticking as I write this post right now! Below I detail recommendations for various forms of writing; you should eventually consider rotating through each of them as part of your routine:</p> <ol> <li>Journaling</li> <li>Blogging</li> <li>Tech Reports/Memos</li> <li>Social Media</li> </ol>","tags":["advice"]},{"location":"2022/07/09/writing-every-day.html#journaling","title":"Journaling","text":"<p>I don't typically mean journaling, but that could be the right starting point for you.</p> <p>First I'd like to get a misconception out of the way: the kind of writing you do matters, but there is no one-size-fits all advice on how you should allocate your time. I've had some students think that writing every day means journaling. </p> <p>There are only 24 hours in a day, so think of the type of writing you choose to do in terms of the opportunity cost of not doing some other type of writing.</p> <p>Example. My undergraduate degree required a great deal of writing and I was developing a strict discipline of time-boxing via the pomodoro technique as part of a larger mindfulness practice at the start of my PhD. Thus when I started my daily writing practice, I did not need to journal, since I was more or less doing this already. Instead, I needed to focus on writing down and synthesizing my thoughts on the things I'd read, concepts I'd struggled with, and generally become more fluent in the language of scientific communication, as it was practiced in my research field. </p> <p>My general advice is: if you already journal, or if journaling is already comfortable to do you, prioritize other writing tasks. If you struggle to get started writing at all, then by all means, journal!</p>","tags":["advice"]},{"location":"2022/07/09/writing-every-day.html#blogging","title":"Blogging","text":"<p>I love blogging: I love doing it, I love the concept of it. What I love about it is that it is absolutely low-stakes: posts should be short (my typical length is probably 2-3 times too long!).  They should be clear and accessible. You can freely admit to not knowing things. You can try out arguments and say things that are wrong. You can take the time and space you need to really explore an idea, and you can punt on the things you don't have time to write about or think about deeply. </p> <p>Students often feel vulnerable when they first approach blogging. I usually assure them that no one is reading their blog posts! What I am really doing when I say this is making a \"security by obscurity\" argument. Of course someone will read your blog posts eventually, but given the sheer quantity of content on the internet, no one is reading them that deeply and no one has the bandwidth, nor inclination to judge you. </p> <p>I'd also note that my most popular blog post has nothing to do with my research; it is a post with instructions on how to incorporate custom javascript in Jekyll blogs. It gets the most hits, has the most comments, and I have occassionally been tweeted at for it. One of the things I love about this is that I wrote something other people found useful, which isn't always the case with research! ;) In any case, this is all kind of cool, but goes to show that you cannot control what people will respond to. </p> <p>So...if no one really reads your posts, what is the point? Here are what I consider the true benefits of blog posts:</p> <p>Blogging provides a way to get \"partial credit.\" Editing involves two distinct tasks: re-writing prose and removing content. </p> <ol> <li>Re-writing prose. It can take time to find the right pitch for your abstract and introduction. With each re-submission, the world changes a little and so it stands to reason that the way we talk about timely problems changes a little. Sometimes we become better at explaining certain concepts. Blog posts can help students (and faculty and research scientists \u2014 anyone, really!) hash out the clearest prose for a particular audience. </li> <li>Removing content. Most venues have a page limit. The page limit ought to map to a contribution of a particular size and there ought to be thematic cohesion in the document submitted. This means that sometimes technical content gets cut. There are sometimes strategic reasons for this (e.g., some advisors advocate reducing \"surface attack area\"), but it's generally best to think about it as a communication challenge: you need to save sufficient space to explain your work and why it matters. Your objective should not be to cram as much technical content into a draft as possible. It can be hard to murder your babies, but with blogging you don't have to!</li> </ol> <p>Potential employers/collaborators/etc. know what you are working on. Publishing work in high-quality venues takes time. Many students in my field take over a year to submit their first paper. This is a problem when applying for internships, fellowships, etc., because it means you have no outward-facing discussions of your work. It can be quite difficult for new researchers to find venues where they can advertise and speak about their work, especially for those who started in the pandemic. Blogging is one way to make that information public. </p> <p>Writing papers gets easier. Many students struggle to write their first paper. Scientific writing uses specialized language and different communities expect papers to have different structure. In addition to the mechanics of what goes into a paper, each research community as has its own dialect. It takes time and practice to build fluency in that dialect. Just as you cannot learn a language passively, you cannot learn to write for a community passively. Lab presentations, invited talks, workshops, and more informal forms of rapid communication (e.g., talking!) are a great ways to build this fluency, which will make writing papers easier!</p>","tags":["advice"]},{"location":"2022/07/09/writing-every-day.html#blogging-as-research-notebook","title":"Blogging as research notebook","text":"<p>One of the primary benefits of blogging your research is that it can function as prior art! Sometimes students fear being scooped. I'm not going to discuss recourse for stolen work here, but junior students should feel confident about sharing their work and establishing a record and timeline via blogging. </p>","tags":["advice"]},{"location":"2022/07/09/writing-every-day.html#tech-memos","title":"Tech memos","text":"<p>Good papers go through many iterations of writing, often via resubmissions. Each venue target may have a different target audience. Time matters too: tastes and attitudes about novelty and worthiness may change dramatically between submissions. </p> <p>What is a tech memo? A tech memo is usually longer than a blog post, and often a bit more formal. While blog posts should be fairly self-contained, tech memos need not be. A short tech memo might eventually correspond to an expanded section of a paper or an appendix. Writing the technical content of an upcoming paper submission as a tech memo can be very helpful for focusing your time and resources on the pitch closer to the deadline. Tech memos can be written as tutorials, proposals, or other forms not quite appropriate for a research paper, but helpful for explaining work done. </p> <p>Why tech memos are useful to you and others.  * How I found them useful. I wrote quite a few tech memos at the end of my PhD. They were helpful for me to work through ideas during the pandemic, when I didn't have many people to talk to. They allowed me to pull on threads that might not go anywhere and be more effective and efficient at creative thinking.  * Ease into paper-writing. First papers aren't just hard because of the actual writing of sentences; it's the whole package of balancing low-level details with high-level vision, of hyping up your work while imagining how Reviewer #2 might interpret what you did, of balancing the theoretical contributions with the empirical contributions. Tech memos don't have to be all things; they can be just one (plus LaTeX practice!). * Protect your work/contributions. Sometimes students leave academia; having a record of tech memos (whether internally or externally) can help the next student who picks up the work, while also clearly establishing you as a co-author. Lab-based tech memo repositories can help with institutional memory vis a vis prior work, preventing churn.</p>","tags":["advice"]},{"location":"2022/07/09/writing-every-day.html#social-media","title":"Social Media","text":"<p>PR writing is the worst.</p> <p>Elevator pitches for your work are incredibly important. I hate these and am very bad at them. I don't get anything out of them when other people pitch them and hate hate hate hate doing this myself. </p> <p>Somewhere (perhaps in an old Twitter account), I have a bookmarked Twitter thread about how to pitch your research on Twitter. Since I cannot find that original thread now, here is a link to an article that looks quite reasonable. </p> <p>I clearly prefer longer-form writing, which probably means I should work on my Twitter game! In any case, tweeting about work (especially in a way non-conversational way) definitely counts as writing!</p>","tags":["advice"]},{"location":"2022/07/09/writing-every-day.html#addendum-there-is-no-one-right-way-to-write","title":"Addendum: There is no one \"right\" way to write!","text":"<p>I've seen many students have anxiety about writing in graduate school. Sometimes this is because they are not native speakers and are self-conscious about their writing. Sometimes this is because their native dialect, while English, is not considered \"proper\" academic writing. I have also seen faculty handle this anxiety poorly and too often contribute to it. </p> <p>My take is that there are two fundamental goals of writing: </p> <ol> <li>Clearly communicate your ideas to an audience.</li> <li>Signal your membership in the in-group to that audience.</li> </ol> <p>Most criticism of writing is a mix of these two. I tend to deal with #1 by asking increasingly detailed questions and expressing that I am the one who is struggling to understand, but that I need their help to explain it to me. I often struggle to communicate new ideas and connections myself and try to model equal partnership in communication. </p> <p>#2 is thorny. I try to separate criticism of voice and style from community norms regarding technical content. The latter includes things the specific section titles, use of <code>\\paragraph{&lt;Topic&gt;.}</code> in papers, community-specific vocabulary, etc. The former is any writing that sounds like an outsider in my internal voice, but where the voice is no impediment to my comprehension. For me this includes overly pedantic requirements regarding punctuation, grammar, and diction that do not change the clarity nor meaning of the text. I could write another blog post on the merits of being explcit about the costs and benefits of adapating one's voice, but this post is too long already!</p>","tags":["advice"]},{"location":"projects/index.html","title":"Projects","text":""},{"location":"projects/index.html#projects","title":"Projects","text":"<p>This list contains both active projects/research areas where I am currently publishing, or inactive projects/research areas that I'd be interested in returning to. I love talking with folks about research and am very happy to start new collaborations, so if any of these topics interest you, please reach out.</p>"},{"location":"projects/index.html#tool-support-for-data-collection","title":"Tool support for data collection","text":"<ul> <li>Experimentation/Experimental Design</li> <li>Surveys</li> </ul>"},{"location":"projects/index.html#tool-support-for-data-analysis-and-interpretation","title":"Tool support for data analysis and interpretation","text":"<ul> <li>Explanation</li> </ul>"},{"location":"projects/index.html#compliance-trust-and-community-support-and-buy-in","title":"Compliance, trust, and community support and buy-in","text":"<ul> <li>PL+Law</li> </ul>"},{"location":"projects/experiments.html","title":"Experimentation","text":""},{"location":"projects/experiments.html#experimentation","title":"Experimentation","text":"<p>What interventional mechanisms do we need to enable citizen science (especially citizen social science!)?</p>"},{"location":"projects/experiments.html#backstory","title":"Backstory!","text":"<p>A few years ago now, Eytan Bakshy designed a domain-specific language for online field experiments, PlanOut. I had the great fortune to intern with him at Facebook, where we investigated possible applications of static analysis to the experimental design space. While we started out focusing on generating contrasts and inferring probability of treatment assignment, we found there were errors and threats to validity of the experiments that only existed at the intersection of programs and experiments. At various points in this project, I worked with UMass folks Emery Berger and Eliot Moss on the PL side of things, and had a wonderful resource in causal inference in David Jensen. I presented this work at NEPLS in 2016 and OOPSLA 2019. It was recognized by my professional organizations via a SIGPLAN research highlight in 2020 and a CACM Research Highlight in 2021 and a grant proposal based on this work was accepted for funding by the NSF as part of the Formal Methods in the Field program. After moving to Northeastern, Chris Martens joined the project as co-PI and has been instrumental in the formal methods aspects of this work.</p>"},{"location":"projects/experiments.html#current-work","title":"Current work","text":"<p>I am currently working with several collaborators on research problems related to programmatically-defined experiments, including but not limited to: robustness checks for p-hacking, type systems for interventions, integration of experiments with passive/observational data collection mechanisms and subsequent data fusion, and inference over proxy variables in systems that do not allow for intervention. </p>"},{"location":"projects/experiments.html#how-to-get-involved","title":"How to get involved","text":"<p>I are interested in developing collaborations with empiricists/domain experts across a variety of computational backgrounds and am specifically looking to apply the tools we have been developing to a working scientist's workflow. I am especially interested in working with faculty and industrial collaborators and can typically fund Northeastern undergraduate coop students. This line of work is particularly central to my research and I am happy to explore other collaboration opportunities. </p> <p>I am also interested in chatting with anyone who is teaching a research methods course to discuss how this work might be useful to you.</p> <p>Please reach out for a meeting with me if you'd like to have a chat.</p>"},{"location":"projects/explanation.html","title":"Explanation","text":""},{"location":"projects/explanation.html#explanation","title":"Explanation","text":"<p>What does it mean to explain the behavior of autonomous agents in time-varying and relational environments?</p>"},{"location":"projects/explanation.html#background","title":"Background","text":"<p>I had been working with longtime collaborators John Foley, Kaleigh Clary, and David Jensen on developing a new testing framework for reinforcement learning back before the pandemic. I designed a prototype version that my collaborators and I used to investigate the behavior of generalized agents in our work, Measuring and Characterizing Generalization in Deep Reinforcement Learning. I presented Toybox at the IBM AI Systems Day and as a poster at the 2018 NeurIPS Systems for ML Workshop. </p>"},{"location":"projects/explanation.html#current-status","title":"Current status","text":"<p>This work is currently on pause due to a lack of resources (personnel, funding, time, compute). Explanation is a notoriously challenging research area and will likely remain relevant in the years to come.</p>"},{"location":"projects/explanation.html#possible-projects","title":"Possible projects","text":"<p>I periodically revisit this work and remain broadly interested in building systems that seek to explain agent behavior in time-varying relational environments and would welcome efforts from students who might be interested in causal reasoning, experimentation, or explanation for autonomtous agents. As this work is not currently core to my research agenda, I would only consider working with exceptionally motivated collaborators on this project. While a background in machine learning and reinforcement learning will undoubtedly be helpful, solid software engineering skills are far more important for this work. If you'd like to discuss project possibilities, reach out.</p>"},{"location":"projects/pl_law.html","title":"PL+Law","text":""},{"location":"projects/pl_law.html#pllaw","title":"PL+Law","text":"<p>Can we infer entailments from legal documents and test whether people understand the implications of what they agree to?</p>"},{"location":"projects/pl_law.html#backstory","title":"Backstory!","text":"<p>In 2021, I began working with Dorsa Mohammadi Arezooji on a new domain in the nascent PL+Law field. We were inspired by Basu et al.'s Property Conveyances as Programming Languages. We began by investigating two domains: arbitration agreements in EULAs and insurance contracts. We were seeking out domain experts in the legal field and have outlined projects in NLP and user comprehension of privacy concerns. Unfortunately due to factors outside her control, Dorsa was not able to pursue her PhD with me. </p> <p>Erin McBride, now a 1L at University of Wisconsin Law School practicing lawyer(!), worked with me in this space, researching contracts of adhesion and their role in changes to websites under experimentation conditions. </p>"},{"location":"projects/pl_law.html#current-work","title":"Current work","text":"<p>I had recently been able to pursue this work under the supervision of Dr. Chris Martens at Northeastern University, as part of Dr. Martens' CAREER award. While our research questions were initially formal in nature, to ground them in real-world scenarios, we took a bit of a detour to better understand how Fediverse administrators who are not necessarily compliance officers understand documents such as privacy policies. Several students have worked on and continue to work on this topic.</p>"},{"location":"projects/pl_law.html#future-work","title":"Future work","text":"<p>Dr. Martens and I remain interested in the question of what formal methods can provide to Fediverse administrators as end-users. We are particularly interested in collaborating with experts in policy and law, including both experts in regulatory compliance (for when we treat administrators as e.g. fiduciaries) and common law (for when we treat administrators as community members involved in disputes). If you'd like to discuss the current and/or future status of this project, please reach out.</p>"},{"location":"projects/surveys.html","title":"Surveys","text":"<p>What are the tradeoffs between detecting adversaries and protecting privacy in survey design?</p>"},{"location":"projects/surveys.html#backstory","title":"Backstory!","text":"<p>Early in my PhD, I designed a table-based programming language and runtime system to design, debug, and deploy scientific surveys on the web. With my project adivsor, I collaborated with folks from the Linguistics department. I first presented SurveyMan at the 2014 Off the Beaten Track workshop. This work won first place at the 2014 PLDI Student Research Competition, a best paper award at OOPSLA 2014, and a 2015 Outstanding Synthesis Award at the University of Massachusetts Amherst. UVM PhD student Michael McConnell resurrected this work with an interest in applying quantitative information flow to surveys to protect potentially vulnerable populations. </p>"},{"location":"projects/surveys.html#current-status","title":"Current status","text":"<p>As a result of serendipitous opportunitites afforded by my UVM colleagues Joe Near, I had returned to this work due to the confluence of student interest in privacy, natural language processing, and biased data collection. Upon leaving UVM, I had to put this work on hold, but am keen to work on it again.</p>"},{"location":"projects/surveys.html#future-projects","title":"Future projects","text":"<p>The release of tools that leverage large langauge models have made some of the more labor-intenstive aspects of this work potentially much lighter. If you would like to discuss further, please reach out.</p>"},{"location":"archive/2025.html","title":"2025","text":""},{"location":"archive/2023.html","title":"2023","text":""},{"location":"archive/2022.html","title":"2022","text":""},{"location":"archive/2021.html","title":"2021","text":""},{"location":"archive/2020.html","title":"2020","text":""},{"location":"category/dsls.html","title":"DSLs","text":""},{"location":"category/helical.html","title":"Helical","text":""},{"location":"category/jupyter.html","title":"Jupyter","text":""},{"location":"category/research.html","title":"Research","text":""},{"location":"category/musings.html","title":"Musings","text":""},{"location":"page/2/index.html","title":"Blog","text":""}]}